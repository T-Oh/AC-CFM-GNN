{
    /*General Settings*/
    "cfg_path":         "",
    "dataset::path":    "",

    /*Data Settings*/
    "data":                 "Zhu_n_minus_k", //Data types: AC, LSTM, Zhu, ANGF_Vcf, LDTSF, LDTSF_DC, n-k, Zhu_nobustype
    "edge_attr":            "Y",    //edge_attr: Y, multi
    "ls_threshold":         0.1,    //Load shed threshold under which only N_below_threshold samples are collected
    "N_below_threshold":    1000,   //Number of samples below the load shed threshold
    "n_scenarios":          10,     //used only for stormsplit should be larger than the largest ID of used scenarios
    "max_seq_length":       5,      //Maximum sequence length for LSTM; in case of autoregressive this defines the window size

    /*General Run Control*/
    "crossvalidation":  false,     //Crossvalidation not implemented for LSTM
    "study::run" :      false,     //Run a study
    "study::continue":  false,     //Continue a study
    "study_ID":         "Test_StateReg",    

    //Specific Run Control
    "checkpointing":    false,     //Not implemented
    "epochs":           100,  
    "output_freq" :     1,         //Output frequency
    "full_output":      true,     //If false only saves 16 random instances
    
    /*Data split settings*/
    "train_size":           1,    //Ignored if stormsplit > 0 otherwise the percentage of data that should be used as training data
    "stormsplit" :          0,     //For stormsplit the files need to be named so that different storms have different IDs i.e. the scenarios of storm 1 should all be named data_1*_*.pt. Then the ID of the storm to be used as training data should be put here
    "test_set::batchsize":  2,
    "train_set::batchsize": 2,
    "train_set::shuffle":   false,

    /*Model Settings*/
    "task":         "StateRegPI",     //GraphReg, GraphClass, NodeReg, typeIIClass, StateReg, StateRegPI (possibly more)
    "model":        "GATLSTM",      //GAT, TAG, GATLSTM, TAGLSTM, GATLSTM, MLPLSTM
    "autoregressive": false,         //If true the model will be autoregressive, only works for LSTM type models (LSTM, GATLSTM, TAGLSTM)

    //Convolutional Settings
    "num_layers":   1,              //Number of convolutional layers
    "hidden_size":  25,             //Embedding size of convolutional layers

    //Regression Head Settings
    "reghead_size":     25,         //Embedding size of regression and classification heads
    "reghead_layers":   1,          //Number of layers of regression and classification heads
    "reghead_type":     "single",   //single, node_edge, node_node_edge
    //LSTM Settings
    "num_conv_targets": 25,         //Embedding size of the final convolutional layer
    "lstm_hidden_size": 25,         //Hidden size of LSTM
    "num_lstm_layers":  1,          //Number of LSTM layers
    //Others
    "dropout":          0.0,
    "use_batchnorm":    false,
    "use_skipcon":      false,
    //GAT Settings
    "num_heads":        2,
    "num_heads":        2,
    "gat_dropout":      0.0,
    //TAG Settings
    "tag_jumps" :       7,

    /*Loss Settings*/
    "gradclip" :            7.1,    //Threshold for Gradient Clipping (if set to 0 no gradient clipping will be performed)
    "use_masking" :         false,  //If true applies node masking to the loss function (not applicable for LSTM)
    "mask_bias" :           1.0,    //Bias for the masking function (not applicable for LSTM)
    "weighted_loss_label":  false,  //If true the loss function will be weighted by the number of samples in the batch
    "weighted_loss_factor": 1,    //Factor for the weighted loss function (if set to 0 no weighting will be performed)
    "PI_factor":            0.5,    //Factor for the power injection loss (only applicable if task is StateRegPI)

    /*Optimizer Settings*/
    "optim::LR":            1e-7,
    "optim::betas":         [0.9, 0.999],
    "optim::epsilon":       1e-8,
    "optim::loss":          "MSE",
    "optim::momentum":      0.99,
    "optim::nesterov":      false,
    "optim::optimizer":     "Adam",
    "optim::weight_decay":  1e-6,

    /*Node2Vec Control*/
    "N2V":                  false,
    "N2V_epochs":           20,
    "embedding_dim" :       16,
    "walk_length" :         5,
    "context_size" :        1,
    "walks_per_node" :      1,
    "num_negative_samples": 1,
    "p" :                   1,
    "q" :                   1,
    
    /*Study Settings*/
    "study::n_trials" :     4,
    "grace_period" :        3,  //Number of epochs to be run at least before Ray decides to kill the trial if performance up to that point is not good enough

    "study::lr::lower": -7,
    "study::lr::upper": -3,

    "study::weight_decay_lower":    -9,
    "study::weight_decay_upper":    -3,

    "study::layers_lower":  1,
    "study::layers_upper":  3,

    "study::hidden_features_lower": 64,
    "study::hidden_features_upper": 64,

    "study::num_conv_targets_lower":    64,
    "study::num_conv_targets_upper":    64,

    "study::lstm_layers_lower": 1,
    "study::lstm_layers_upper": 3,

    "study::lstm_hidden_size_lower":    16,
    "study::lstm_hidden_size_upper":    128,

    "study::dropout_lower": 0.5,
    "study::dropout_upper": 0.5,

    "study::gradclip_lower":    0.0,
    "study::gradclip_upper":    10.0,

    "study::reghead_size_lower":    16,
    "study::reghead_size_upper":    256,

    "study::reghead_layers_lower":  1,
    "study::reghead_layers_upper":  3,
    "study::reghead_type": true,
    
    "study::batchnorm": true,

    "study::skipcon":   true,

    "study::masking":   false,
    "study::mask_bias_lower":   0.5,
    "study::mask_bias_upper":   0.5,

    "study::loss_weight_lower": 0.02,
    "study::loss_weight_upper": 1,

    "study::heads_lower":   2,
    "study::heads_upper":   2,

    "study::gat_dropout_lower": 0.5,
    "study::gat_dropout_upper": 0.5,

    "study::tag_jumps_lower":   10,
    "study::tag_jumps_upper":   10,

    "study::loss_type": false,

    //Node2Vec Study Settings
    "study::embedding_dim_lower" : 32,
    "study::embedding_dim_upper" : 32,
    "study::walk_length_lower" : 30,
    "study::walk_length_upper" : 30,
    "study::context_size_lower" : 2,
    "study::context_size_upper" : 2,
    "study::walks_per_node_lower" : 2,
    "study::walks_per_node_upper" : 2,
    "study::num_negative_samples_lower" : 2,
    "study::num_negative_samples_upper" : 2,
    "study::p_lower" : 2,
    "study::p_upper" : 2,
    "study::q_lower" : 2,
    "study::q_upper" : 2,

    /*Others*/
    "manual_seed" : 7,
    "accuracy_tolerance":0.15,


    "supernode" : false,

    /*for per unit use "multiply_base_voltage": false and "normalize_injection" : true*/
    "normalize_injection" : true,
    "multiply_base_voltage": false,
    "zhu_check_buses" :  false,
    "check_s_y" : false,

    /*Zhu*/
    "pl_w1": 1,
    "pl_w2": 1,
    "pl_w3": 1,
    "pl_simply_train": false,
    "physics_loss": true,
    "pl_stage": "pretrain"
}
